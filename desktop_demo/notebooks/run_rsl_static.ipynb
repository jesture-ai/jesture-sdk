{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand tracking skeleton (Mac OS X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shutil.which(\"libSystem.B.dylib\"): None\n",
      "ctypes.CDLL(\"libSystem.B.dylib\")._name: libSystem.B.dylib\n",
      "ctypes.__version__: 1.1.0\n",
      "platform.mac_ver(): ('10.16', ('', '', ''), 'x86_64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(MainThread) Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "(MainThread) Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2.__version__: 3.4.3\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from src.utils import load_image_with_alpha, overlay_alpha\n",
    "from src.utils import draw_text, draw_multiline_text, draw_skeleton\n",
    "from src.thread_camera_draw import ThreadCameraDraw\n",
    "\n",
    "from jesture_sdk_python.jesture_sdk_python import JestureSdkRunner\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print('cv2.__version__:', cv2.__version__)  # 4.1.2 recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(MainThread) STREAM b'IHDR' 16 13\n",
      "(MainThread) STREAM b'IDAT' 41 8192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 250 pixels from up and down borders\n",
      "Original image size: (1920, 580)\n",
      "Target size: (192, 58)\n"
     ]
    }
   ],
   "source": [
    "# create the application window\n",
    "name = 'RSL: 10 static gestures'\n",
    "width, height = (640, 480)  # (1280, 720)\n",
    "cv2.namedWindow(name)\n",
    "# cv2.resizeWindow(name, (width, height))\n",
    "cv2.startWindowThread()\n",
    "\n",
    "# set the data file\n",
    "now = datetime.datetime.now()\n",
    "dt = f'{now.day:02d}{now.month:02d}{now.year%100:02d}_{now.hour:02d}_{now.minute:02d}'\n",
    "data_file_name = f'hand_kps_v1_{dt}.pkl'\n",
    "\n",
    "# set the logo stuff\n",
    "logo_path = f'../images/jesture_logo.png'\n",
    "logo_img, logo_alpha = load_image_with_alpha(logo_path, remove_borders=True)\n",
    "logo_loc = (10, 10)\n",
    "\n",
    "# set the gestures help stuff\n",
    "key_to_idx = {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5,\n",
    "              '6': 6, '7': 7, '8': 8, '9': 9, 'f': 10, 'z': 11}\n",
    "key_ords = [ord(x) for x in key_to_idx]\n",
    "idx_to_gesture = {0: 'Жест \"А\"', 1: 'Жест \"Б\"', 2: 'Жест \"В\"', 3: 'Жест \"Г\"', 4: 'Жест \"Е\"', 5: 'Жест \"Ж\"', \n",
    "                  6: 'Жест \"И\"', 7: 'Жест \"Л\"', 8: 'Жест \"М\"', 9: 'Жест \"Н\"', 10: 'Жест \"Я\"', 11: 'Нет жеста'}\n",
    "idx_to_count = {k: 0 for k in idx_to_gesture}\n",
    "# help_textlist = [f'{k}: {idx_to_gesture[key_to_idx[k]]} {idx_to_count[key_to_idx[k]]}' for k in key_to_idx]\n",
    "# help_textlist_str = '\\n'.join(help_textlist)\n",
    "\n",
    "help_box_width = 175\n",
    "help_box_tl = {'right': (10, height//5+10), \n",
    "               'left': (width-help_box_width, height//5+10)}\n",
    "help_box_br = {'right': (10+help_box_width, height-30), \n",
    "               'left': (width, height-30)}\n",
    "help_text_loc = {'right': (help_box_tl['right'][0]+10, help_box_tl['right'][1]+10),\n",
    "                 'left': (help_box_tl['left'][0]+10, help_box_tl['left'][1]+10)}\n",
    "help_font = ImageFont.truetype(\"Comfortaa-Light.ttf\", 20)\n",
    "\n",
    "# set the scaled hands stuff\n",
    "mid_hand_box_tl = (width//3, height-height//5)\n",
    "mid_hand_box_br = (2*width//3, height)\n",
    "hand_box_tl = {'right': (2*width//3, height-height//5),\n",
    "               'left': (0, height-height//5)}\n",
    "hand_box_br = {'right': (width, height),\n",
    "               'left': (width//3, height)}\n",
    "\n",
    "# set the hand type stuff\n",
    "handtype_text = {\"right\": \"Right hand capture (L/R)\", \n",
    "                 \"left\": \"Left hand capture (L/R)\"}\n",
    "handtype_text_loc = (width//2, 25)\n",
    "\n",
    "# set the counter stuff\n",
    "count_text_loc = (width//3, 25)\n",
    "\n",
    "# set common font\n",
    "font = ImageFont.truetype(\"../fonts/Comfortaa-Light.ttf\", 24)\n",
    "\n",
    "# variables used in the main loop\n",
    "pressed_duration = 0\n",
    "pressed_text = ''\n",
    "\n",
    "selfie_mode = True\n",
    "hand_type = 'right'\n",
    "data_list = []\n",
    "prev_k = ''\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# model_path = '/Users/izakharkin/Desktop/jesture_sdk/desktop_demo/notebooks/rsl_models/rsl_fc256.tflite'\n",
    "\n",
    "# # Load the TFLite model and allocate tensors.\n",
    "# interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "# interpreter.allocate_tensors()\n",
    "\n",
    "# # Get input and output tensors.\n",
    "# input_details = interpreter.get_input_details()\n",
    "# output_details = interpreter.get_output_details()\n",
    "\n",
    "# # Test the model on random input data.\n",
    "# input_shape = input_details[0]['shape']\n",
    "# input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "# interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "# interpreter.invoke()\n",
    "\n",
    "# # The function `get_tensor()` returns a copy of the tensor data.\n",
    "# # Use `tensor()` in order to get a pointer to the tensor.\n",
    "# output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "# print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RslRecognizer(object):\n",
    "    def __init__(self, model_path):\n",
    "        self.model = tf.lite.Interpreter(model_path=model_path)\n",
    "        self.model.allocate_tensors()\n",
    "        self.input_details = self.model.get_input_details()\n",
    "        self.output_details = self.model.get_output_details()\n",
    "        self.input_shape = self.input_details[0]['shape']\n",
    "        self.output_shape = self.output_details[0]['shape']\n",
    "        print('Initialized model:')\n",
    "        print('Input shape: {}'.format(self.input_shape))\n",
    "        print('Output shape: {}'.format(self.output_shape))\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        x = x.astype('float32')\n",
    "        self.model.set_tensor(self.input_details[0]['index'], x)\n",
    "        self.model.invoke()\n",
    "        output_data = self.model.get_tensor(self.output_details[0]['index'])\n",
    "        return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized model:\n",
      "Input shape: [ 1 63]\n",
      "Output shape: [ 1 12]\n",
      "CPU times: user 2.61 ms, sys: 1.65 ms, total: 4.26 ms\n",
      "Wall time: 6.41 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -98.0575  ,  -24.879929, -156.98726 , -122.52011 ,   19.554266,\n",
       "         -92.070366,  -99.12113 , -102.96895 ,  -85.96015 , -133.84106 ,\n",
       "         -58.017197,   81.37131 ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_path = '/Users/izakharkin/Desktop/jesture_sdk/desktop_demo/notebooks/rsl_models/rsl_fc256.tflite'\n",
    "rsl_model = RslRecognizer(model_path)\n",
    "rsl_model(np.array(np.random.random_sample((1, 63)), dtype=np.float32)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.cam_id = 1\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(MainThread) [JestureSdkRunner] Instance created.\n",
      "(jesture_sdk_python_thread) [JestureSdkRunner] Starting recognition...\n",
      "(MainThread) [JestureSdkRunner] Recognition thread started.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<jesture_sdk_python.jesture_sdk_python.JestureSdkRunner at 0x7fb1e43ab090>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start Jesture SDK Python runner\n",
    "jesture_runner = JestureSdkRunner(cam_id=args.cam_id)\n",
    "jesture_runner.start_recognition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jesture_runner.stop_recognition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(MainThread) [ThreadCameraDraw] Starting a thread...\n",
      "(MainThread) [ThreadCameraDraw] Thread started.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.thread_camera_draw.ThreadCameraDraw at 0x7fb1e43ab950>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# start reading frames to display in the application window\n",
    "cap = ThreadCameraDraw(\n",
    "    jesture_runner, cam_id=args.cam_id, width=width, height=height,\n",
    "    hand_box_tl=mid_hand_box_tl, hand_box_br=mid_hand_box_br,\n",
    "    draw_hand_box=False\n",
    ")\n",
    "cap.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera params was set to: 640 480\n",
      "Real params are: 640 480\n",
      "[[3.99747505e+02 4.32579861e+02 0.00000000e+00]\n",
      " [4.02027206e+02 3.86234865e+02 7.23224357e-02]\n",
      " [3.88932304e+02 3.55716820e+02 1.04062103e-01]\n",
      " [3.71003113e+02 3.40915318e+02 1.28224492e-01]\n",
      " [3.57925911e+02 3.41868153e+02 1.49324834e-01]\n",
      " [3.70422516e+02 3.26005154e+02 3.26330103e-02]\n",
      " [3.41546249e+02 3.21315079e+02 8.60392079e-02]\n",
      " [3.44774818e+02 3.38938837e+02 1.20710135e-01]\n",
      " [3.54043503e+02 3.47615376e+02 1.30775496e-01]\n",
      " [3.55284195e+02 3.41665993e+02 9.04347096e-03]\n",
      " [3.25715637e+02 3.44914999e+02 7.50071853e-02]\n",
      " [3.32706413e+02 3.61656418e+02 1.07540719e-01]\n",
      " [3.43767281e+02 3.68349581e+02 1.07799232e-01]\n",
      " [3.42104111e+02 3.64345579e+02 0.00000000e+00]\n",
      " [3.16164360e+02 3.65026188e+02 5.68275191e-02]\n",
      " [3.23803139e+02 3.80545235e+02 8.30179825e-02]\n",
      " [3.35031090e+02 3.89058352e+02 7.93376788e-02]\n",
      " [3.31333923e+02 3.90686960e+02 0.00000000e+00]\n",
      " [3.07499733e+02 3.82400036e+02 2.90447623e-02]\n",
      " [3.15044689e+02 3.92838678e+02 4.90640849e-02]\n",
      " [3.26304588e+02 4.01845493e+02 5.19027859e-02]]\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(MainThread) [ThreadCameraDraw] Stopping...\n",
      "(Camera-Draw Python Thread) [ThreadCameraDraw] Frame loop finished.\n",
      "(Camera-Draw Python Thread) [ThreadCameraDraw] Capture released.\n",
      "(MainThread) [ThreadCameraDraw] Camera thread joined.\n",
      "(MainThread) [JestureSdkRunner] Stopping recognition...\n",
      "(MainThread) [JestureSdkRunner] Recognition stopped.\n",
      "(MainThread) [JestureSdkRunner] Thread joined.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "help_textlist = [f'{idx_to_gesture[key_to_idx[k]]}' for k in key_to_idx]\n",
    "help_textlist_str = '\\n'.join(help_textlist)\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "while(True):\n",
    "    if cap.frame is None:\n",
    "        continue\n",
    "        \n",
    "#     cap.hand_box_tl = hand_box_tl[hand_type]\n",
    "#     cap.hand_box_br = hand_box_br[hand_type]\n",
    "    \n",
    "    # get current webcam image with drawn hand skeletons\n",
    "    frame = cap.frame[:,::-1,:] if selfie_mode else cap.frame\n",
    "    \n",
    "    # draw logo\n",
    "#     frame = overlay_alpha(logo_img[:,:,::-1], logo_alpha, frame, loc=logo_loc, alpha=1.0)\n",
    "    \n",
    "    # recognize current static gesture\n",
    "    scaled_kps = jesture_runner.get_hand_keypoints(f'scaled_{hand_type}_keypoints')\n",
    "    gesture_id = rsl_model(scaled_kps.reshape(1, -1))[0].argmax()\n",
    "    \n",
    "    # draw ui elements\n",
    "    frame = Image.fromarray(frame if type(np.array([])) == type(frame) else frame.get())\n",
    "    draw = ImageDraw.Draw(frame, \"RGBA\")\n",
    "    draw.rectangle((help_box_tl[hand_type], help_box_br[hand_type]), \n",
    "                   fill=(0, 0, 0, 127), outline=(235, 190, 63, 255))\n",
    "    # draw.rectangle((hand_box_tl, hand_box_br), fill=(0, 0, 0, 127), outline=(235, 190, 63, 255))\n",
    "    \n",
    "    # draw text\n",
    "    draw.multiline_text(handtype_text_loc, handtype_text[hand_type], \n",
    "                        font=font, fill=(255, 255, 255, 200))\n",
    "    \n",
    "    draw.multiline_text(help_text_loc[hand_type], help_textlist_str, \n",
    "                        font=help_font, fill=(255, 255, 255))\n",
    "    \n",
    "    # retrieve keyboard signal\n",
    "    c = cv2.waitKey(1) % 256\n",
    "    if c == ord('q'):\n",
    "        break\n",
    "        \n",
    "    if c == ord('l'):\n",
    "        hand_type = 'left'\n",
    "    if c == ord('r'):\n",
    "        hand_type = 'right'\n",
    "    \n",
    "    # retrieve if gesture key is pressed\n",
    "#     k, v = chr(c), idx_to_gesture[gesture_id]\n",
    "    pressed_text = f'{idx_to_gesture[gesture_id]}'\n",
    "#     idx_to_count[key_to_idx[k]] += 1\n",
    "#     pressed_duration = 4\n",
    "#     print(f\"pressed {pressed_text}, shape: {frame.size}\")\n",
    "    \n",
    "    # draw notification text if key was pressed less then 12 frames ago\n",
    "#     if pressed_duration > 0:\n",
    "    notify_textlist_str = \"\\n\".join(\n",
    "        [x if x == pressed_text else \"\" for x in help_textlist])\n",
    "    draw.multiline_text(help_text_loc[hand_type], notify_textlist_str, \n",
    "                        font=help_font, fill=(235, 190, 63))\n",
    "#         pressed_duration -= 1\n",
    "   \n",
    "    frame = np.array(frame).astype(np.uint8)\n",
    "    cv2.imshow(name, frame)\n",
    "            \n",
    "    i += 1\n",
    "\n",
    "\n",
    "# with open(data_file_name, 'wb') as file:\n",
    "#     print(f'Dumping {len(data_list)} items to {data_file_name}...')\n",
    "#     pickle.dump(data_list, file)\n",
    "#     print(f'Dumped.')\n",
    "    \n",
    "\n",
    "cap.stop()\n",
    "jesture_runner.stop_recognition()\n",
    "\n",
    "cv2.waitKey(1)\n",
    "cv2.destroyWindow(name)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.stop()\n",
    "jesture_runner.stop_recognition()\n",
    "\n",
    "cv2.waitKey(1)\n",
    "# cv2.destroyWindow(name)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# data_file_name = '../out_data/robot_hand_keypoints_120421_03_26.pkl'\n",
    "\n",
    "# with open(data_file_name, 'rb') as file:\n",
    "#     loaded_data = pickle.load(file)\n",
    "\n",
    "# print(len(loaded_data))\n",
    "# print(loaded_data[:3], loaded_data[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://unicode.org/emoji/charts/emoji-list.html#1f44c\n",
    "gesture_to_emoji = {\n",
    "    '': '',\n",
    "    '———': '———',\n",
    "    'ONE': '\\U0000261D',\n",
    "    'TWO': 'TWO',\n",
    "    'THREE': 'THREE',\n",
    "    'FOUR': 'FOUR',\n",
    "    'FIVE' : '\\U0001F590',\n",
    "    'OK': '\\U0001F44C',\n",
    "    'YEAH': '\\U0000270C',\n",
    "    'SPIDERMAN': '\\U0001F91F',\n",
    "    'ROCK': '\\U0001F918',\n",
    "    'FIST': '\\U00009270A'\n",
    "}\n",
    "\n",
    "# !pip install emoji\n",
    "import unicodedata\n",
    "# in python2 use u'\\U0001f603'\n",
    "print('\\U0001F44C')#U+1F44C\n",
    "print(gesture_to_emoji['FIVE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_logo_alpha():\n",
    "    design_root = '/Users/izakharkin/Desktop/deepjest/_design'\n",
    "    logo_path = f'{design_root}/wix/jesture_ai_logo_comfortaa/jesture_logo_comfortaa-removebg.png'\n",
    "\n",
    "    logo_img, logo_alpha = load_image_with_alpha(logo_path, remove_borders=True)\n",
    "\n",
    "    plt.imshow(logo_img);\n",
    "    plt.show();\n",
    "    plt.imshow(logo_alpha, cmap='gray');\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_overlay():\n",
    "    testimg = io.imread('./test.jpg')\n",
    "    testimg = overlay_alpha(logo_img, logo_alpha, testimg, loc=(10, 10), alpha=1.0)\n",
    "\n",
    "    idx_to_gesture = {1: 'one', 2: 'two', 3: 'three', 4: 'four', 5: 'five',\n",
    "                      6: 'fist', 7: 'piece', 8: 'love', 9: 'ok', 0: 'horns'}\n",
    "    help_textlist = [f'{k}: {v}' for k, v in idx_to_gesture.items()]\n",
    "    testimg = draw_multiline_text(testimg, help_textlist)\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.imshow(testimg);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_blackbox():\n",
    "    blackbox = io.imread('./blackbox.png')\n",
    "    orig_size = (blackbox.shape[1], blackbox.shape[0])\n",
    "    print('orig_size:', orig_size)\n",
    "    target_size = (orig_size[0] // 7, orig_size[1] // 7)\n",
    "    print('target_size:', target_size)\n",
    "    blackbox = cv2.resize(blackbox, target_size)\n",
    "    plt.imshow(blackbox);\n",
    "    plt.show();\n",
    "\n",
    "    blackbox_alpha = np.ones_like(blackbox)[:,:,0] * 255\n",
    "    blackbox_alpha[blackbox[:,:,0] == 255] = 0\n",
    "    plt.imshow(blackbox_alpha, cmap='gray');\n",
    "    plt.show();\n",
    "\n",
    "    testimg = overlay_alpha(blackbox, blackbox_alpha, testimg, loc=(10, 100), alpha=1.0)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.imshow(testimg);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pil_draw():\n",
    "    testimg = io.imread('./test.jpg')\n",
    "    testimg = Image.fromarray(testimg)\n",
    "    draw = ImageDraw.Draw(testimg, \"RGBA\")\n",
    "    draw.rectangle(((280, 10), (1010, 706)), fill=(0, 0, 0, 127))\n",
    "    draw.rectangle(((280, 10), (1010, 706)), outline=(63, 190, 235, 127))\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(np.array(testimg));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf20]",
   "language": "python",
   "name": "conda-env-tf20-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
